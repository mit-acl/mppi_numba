{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Mon_May__3_19:15:13_PDT_2021\n",
      "Cuda compilation tools, release 11.3, V11.3.109\n",
      "Build cuda_11.3.r11.3/compiler.29920130_0\n",
      "name = b'NVIDIA GeForce RTX 3070 Ti Laptop GPU'\n",
      "maxThreadsPerBlock = 1024\n",
      "maxBlockDimX = 1024\n",
      "maxBlockDimY = 1024\n",
      "maxBlockDimZ = 64\n",
      "maxGridDimX = 2147483647\n",
      "maxGridDimY = 65535\n",
      "maxGridDimZ = 65535\n",
      "maxSharedMemoryPerBlock = 49152\n",
      "asyncEngineCount = 2\n",
      "canMapHostMemory = 1\n",
      "multiProcessorCount = 46\n",
      "warpSize = 32\n",
      "unifiedAddressing = 1\n",
      "pciBusID = 1\n",
      "pciDeviceID = 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection, PolyCollection\n",
    "from matplotlib.patches import Ellipse\n",
    "from collections import namedtuple\n",
    "\n",
    "!nvcc --version\n",
    "\n",
    "import numba\n",
    "from numba import cuda\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32, xoroshiro128p_normal_float32\n",
    "\n",
    "gpu = cuda.get_current_device()\n",
    "print(\"name = %s\" % gpu.name)\n",
    "print(\"maxThreadsPerBlock = %s\" % str(gpu.MAX_THREADS_PER_BLOCK))\n",
    "print(\"maxBlockDimX = %s\" % str(gpu.MAX_BLOCK_DIM_X))\n",
    "print(\"maxBlockDimY = %s\" % str(gpu.MAX_BLOCK_DIM_Y))\n",
    "print(\"maxBlockDimZ = %s\" % str(gpu.MAX_BLOCK_DIM_Z))\n",
    "print(\"maxGridDimX = %s\" % str(gpu.MAX_GRID_DIM_X))\n",
    "print(\"maxGridDimY = %s\" % str(gpu.MAX_GRID_DIM_Y))\n",
    "print(\"maxGridDimZ = %s\" % str(gpu.MAX_GRID_DIM_Z))\n",
    "print(\"maxSharedMemoryPerBlock = %s\" % str(gpu.MAX_SHARED_MEMORY_PER_BLOCK))\n",
    "print(\"asyncEngineCount = %s\" % str(gpu.ASYNC_ENGINE_COUNT))\n",
    "print(\"canMapHostMemory = %s\" % str(gpu.CAN_MAP_HOST_MEMORY))\n",
    "print(\"multiProcessorCount = %s\" % str(gpu.MULTIPROCESSOR_COUNT))\n",
    "print(\"warpSize = %s\" % str(gpu.WARP_SIZE))\n",
    "print(\"unifiedAddressing = %s\" % str(gpu.UNIFIED_ADDRESSING))\n",
    "print(\"pciBusID = %s\" % str(gpu.PCI_BUS_ID))\n",
    "print(\"pciDeviceID = %s\" % str(gpu.PCI_DEVICE_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal unicycle model\n",
    "def normalize_angle(th):\n",
    "    pi_2 = 2*np.pi\n",
    "    # reduce the angle  \n",
    "    th =  th % pi_2; \n",
    "\n",
    "    # force it to be the positive remainder, so that 0 <= angle < 360  \n",
    "    th = (th + pi_2) % (pi_2);  \n",
    "\n",
    "    # force into the minimum absolute value residue class, so that -180 < angle <= 180  \n",
    "    if th > np.pi:\n",
    "        th -= pi_2\n",
    "\n",
    "    return th\n",
    "\n",
    "def normalize_angle_np(th):\n",
    "    pi_2 = 2*np.pi\n",
    "    # reduce the angle  \n",
    "    th =  th % pi_2; \n",
    "\n",
    "    # force it to be the positive remainder, so that 0 <= angle < 360  \n",
    "    th = (th + pi_2) % (pi_2);  \n",
    "\n",
    "    # force into the minimum absolute value residue class, so that -180 < angle <= 180  \n",
    "    mask = (th > np.pi)\n",
    "    th[mask] = th[mask] - pi_2\n",
    "\n",
    "    return th\n",
    "\n",
    "\n",
    "def vis_density(ax, density, terrain, vis_cvar_alpha, color='b', title=None, hist_alpha=0.5):\n",
    "    cvar, thres = density.cvar(alpha=vis_cvar_alpha)\n",
    "    if density.sample_initialized:\n",
    "        ax.hist(density.samples, bins=100, density=True, color=color, alpha=hist_alpha, label=terrain.name)\n",
    "    ax.plot([thres, thres], [0,5], 'k--', label='{}-th Percentile'.format(int(vis_cvar_alpha*100.0)),\n",
    "           linewidth=2)\n",
    "    if density.sample_bounds is not None:\n",
    "        ax.set_xlim(density.sample_bounds)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "        \n",
    "        \n",
    "    ax.set_xlabel(\"Speed (m/s)\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "        \n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "def vis_density_as_pmf(ax, density, terrain, num_bins, include_min_max=True, color='b', title=None, hist_alpha=0.5):\n",
    "    values, pmf = density.get_pmf(num_bins=num_bins, include_min_max=include_min_max)\n",
    "    markerline, stemlines, baseline  = ax.stem(values, pmf, label=terrain.name)\n",
    "    markerline.set_color(color)\n",
    "    stemlines.set_color(color)\n",
    "    baseline.set_color('r')\n",
    "    if density.pmf_bounds is not None:\n",
    "        ax.set_xlim(density.pmf_bounds)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(\"Speed (m/s)\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Density(object):\n",
    "    \n",
    "    def __init__(self, sample_bounds, pmf_bounds, sample_fn, num_samples=1e4):\n",
    "        self.sample_bounds = sample_bounds # bound within which to sample\n",
    "        self.pmf_bounds = pmf_bounds # bound within which to extract the PMF\n",
    "        self.sample_fn = sample_fn\n",
    "        self.num_samples = num_samples # num samples for estimating different values\n",
    "\n",
    "        self.sample_initialized = False\n",
    "        self.initialize_samples(self.num_samples)\n",
    "        self.sample_initialized = False\n",
    "        self.samples = None\n",
    "            \n",
    "    def initialize_samples(self, num_samples):\n",
    "        self.samples = self.sample(num_samples)\n",
    "        self.sample_initialized = True\n",
    "\n",
    "    def mean(self, samples=None):\n",
    "        if samples is not None:\n",
    "            return np.mean(samples)\n",
    "        else:\n",
    "            if not self.sample_initialized:\n",
    "                self.initialize_samples(self.num_samples)\n",
    "            return np.mean(self.samples)\n",
    "\n",
    "    def var(self, samples=None):\n",
    "        if samples is not None:\n",
    "            return np.var(samples)\n",
    "        else:\n",
    "            if not self.sample_initialized:\n",
    "                self.initialize_samples(self.num_samples)\n",
    "            return np.var(self.samples)\n",
    "    \n",
    "    def cvar(self, alpha, front=True, samples=None):\n",
    "        assert alpha>0 and alpha<=1.0, \"Alpha must be in (0,1]\"\n",
    "            \n",
    "        p = alpha*100.0 if front else (1.0-alpha)*100.0\n",
    "        if samples is None:\n",
    "            if not self.sample_initialized:\n",
    "                self.initialize_samples(self.num_samples)\n",
    "            samples = self.samples\n",
    "\n",
    "        thres = np.percentile(samples, p)\n",
    "        if front:\n",
    "            mask = samples<thres\n",
    "        else:\n",
    "            mask = samples>thres\n",
    "        assert np.sum(mask)>0\n",
    "        return np.mean(samples[mask]), thres\n",
    "    \n",
    "    def sample(self, num):\n",
    "        return self.sample_fn(num)\n",
    "\n",
    "    def get_pmf(self, num_bins, include_min_max=True):\n",
    "        # For convenience, mass for min and max values are added as separate bins\n",
    "        if not self.sample_initialized:\n",
    "            self.initialize_samples(self.num_samples)\n",
    "        vrange = self.pmf_bounds\n",
    "        nums, edges = np.histogram(self.samples, num_bins, range=vrange, density=True)\n",
    "\n",
    "        bin_width = (vrange[1]-vrange[0])/num_bins\n",
    "        values = np.arange(vrange[0], vrange[1], bin_width) + bin_width/2\n",
    "\n",
    "        if include_min_max:\n",
    "            # Insert minimum value at the beginning (useful for 0 traction elements)\n",
    "            values = np.insert(values, 0, vrange[0])\n",
    "            nums = np.insert(nums, 0, 0)\n",
    "            # Insert max value at the end (useful for nominal model that attains max values)\n",
    "            values = np.append(values, vrange[1])\n",
    "            nums = np.append(nums, 0)\n",
    "\n",
    "        # Return (values, pmf)\n",
    "        return values, nums/np.sum(nums)\n",
    "\n",
    "\n",
    "class GaussianMixture(Density):\n",
    "\n",
    "    def __init__(self, sample_bounds, pmf_bounds, weights, means, stds, num_samples=1e3):\n",
    "        assert sum(weights)==1\n",
    "        assert len(weights)==len(means)==len(stds)\n",
    "        assert len(sample_bounds)==2\n",
    "        assert len(pmf_bounds)==2\n",
    "        assert sample_bounds[1]>=sample_bounds[0]\n",
    "        assert pmf_bounds[1]>=pmf_bounds[0]\n",
    "        assert pmf_bounds[0]<=sample_bounds[0] and pmf_bounds[1]>=sample_bounds[1]\n",
    "        self.num_components = len(weights)\n",
    "        \n",
    "        def sample_fn(num):\n",
    "           # Sample from mixture of Gaussian truncated between range\n",
    "            num_sampled = 0\n",
    "            data = []\n",
    "            # indices = np.arange(len(weights))\n",
    "            while num_sampled < num:\n",
    "                idx = np.random.choice(self.num_components, p=weights)\n",
    "                sample = np.random.normal(loc=means[idx], scale=stds[idx])\n",
    "                if sample >= sample_bounds[0] and sample <= sample_bounds[1]:\n",
    "                    data.append(sample)\n",
    "                    num_sampled += 1 \n",
    "            return np.asarray(data)\n",
    "        \n",
    "        super().__init__(sample_bounds, pmf_bounds, sample_fn, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terrain type has linear and angular traction parameters\n",
    "class Terrain(object):\n",
    "    def __init__(self, name, rgb, lin_density, ang_density, cvar_alpha=0.1, cvar_front=True, num_saved_samples=1e4):\n",
    "        self.name = name\n",
    "        self.lin_density = lin_density\n",
    "        self.ang_density = ang_density\n",
    "        self.num_saved_samples = num_saved_samples\n",
    "        self.lin_saved_samples = self.lin_density.sample(num_saved_samples)\n",
    "        self.ang_saved_samples = self.ang_density.sample(num_saved_samples)\n",
    "        \n",
    "        self.cvar_alpha = cvar_alpha\n",
    "        self.cvar_front = cvar_front\n",
    "        self.rgb = rgb\n",
    "        \n",
    "        # Save statistics\n",
    "        self.lin_mean = self.lin_density.mean(self.lin_saved_samples)\n",
    "        self.lin_var = self.lin_density.var(self.lin_saved_samples)\n",
    "        self.lin_std = np.sqrt(self.lin_var)\n",
    "        self.lin_cvar, self.lin_cvar_thres = self.lin_density.cvar(self.cvar_alpha, samples=self.lin_saved_samples, front=cvar_front)\n",
    "\n",
    "        self.ang_mean = self.ang_density.mean(self.ang_saved_samples)\n",
    "        self.ang_var = self.ang_density.var(self.ang_saved_samples)\n",
    "        self.ang_std = np.sqrt(self.ang_var)\n",
    "        self.ang_cvar, self.ang_cvar_thres = self.ang_density.cvar(self.cvar_alpha, samples=self.ang_saved_samples, front=cvar_front)\n",
    "\n",
    "    def update_cvar_alpha(self, alpha):\n",
    "        assert alpha>0 and alpha<=1.0\n",
    "        self.cvar_alpha = alpha\n",
    "        self.lin_cvar, self.lin_cvar_thres = self.lin_density.cvar(self.cvar_alpha, samples=self.lin_saved_samples, front=self.cvar_front)\n",
    "        self.ang_cvar, self.ang_cvar_thres = self.ang_density.cvar(self.cvar_alpha, samples=self.ang_saved_samples, front=self.cvar_front)\n",
    "    \n",
    "    def sample_traction(self, num_samples):\n",
    "        lin_samples = self.lin_density.sample(num_samples)\n",
    "        ang_samples = self.ang_density.sample(num_samples)\n",
    "        return lin_samples, ang_samples\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # return \"Terrain {} has mean={:.2f}, std={:.2f}, cvar({:.2f})={:.2f} (computed from {} saved samples)\".format(\n",
    "        #     self.name, self.mean, self.std, self.cvar_alpha, self.cvar, self.num_saved_samples)\n",
    "        return \"Terrain {} has the following properties for linear and angular tractions.\\n\".format(self.name) + \\\n",
    "                \"mean=({:.2f}, {:.2f}), std=({:.2f}, {:.2f}), cvar({:.2f})=({:.2f}, {:.2f}) (computed from {} saved samples)\".format(\n",
    "                    self.lin_mean, self.ang_mean, self.lin_std, self.ang_std, self.cvar_alpha, self.lin_cvar, self.ang_cvar, self.num_saved_samples\n",
    "                )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Traction Distribution Map (TDM) leveraging Numba to pre-allocate memory on GPU.\n",
    "Internal storage is in the form of (num_bins, height, width) int8 0~100 normalized between min and max traction values (typically 0~1).\n",
    "\"\"\"\n",
    "num_grid_samples = 1024\n",
    "class TDM_Numba(object):\n",
    "\n",
    "    NUM_GRID_SAMPLES = num_grid_samples\n",
    "    BLOCK_DIM = (1, NUM_GRID_SAMPLES)\n",
    "    THREAD_DIM = (16, 16) # (32, 32)\n",
    "    TOTAL_THREADS = NUM_GRID_SAMPLES*THREAD_DIM[0]*THREAD_DIM[1]\n",
    "\n",
    "    def __init__(self, max_speed, dt):\n",
    "\n",
    "        # Used for padding 0 traction regions around the map\n",
    "        self.max_speed = max_speed\n",
    "        self.dt = dt\n",
    "        self.num_cells_to_pad = None\n",
    "\n",
    "\n",
    "        # For initialization from semantic grid (for sim benchmarks only)\n",
    "        self.semantic_grid = None # semantic_grid # semantic ids\n",
    "        self.semantic_grid_initialized = False\n",
    "        self.id2name = None # dict[semantic_id]=>name\n",
    "        self.name2terrain = None # dict[name]=>Terrain object\n",
    "        self.id2terrain_fn = None\n",
    "        self.terrain2pmf = None\n",
    "\n",
    "        # Set the properties for pmf_grid.\n",
    "        # For now, assume all pmf has the same range\n",
    "        self.pmf_grid = None\n",
    "        self.bin_values = None\n",
    "        self.bin_values_bounds = None\n",
    "        self.pmf_grid_d = None # data on device\n",
    "        self.bin_values_d = None\n",
    "        self.bin_values_bounds_d = None\n",
    "        self.num_pmf_bins = None\n",
    "        self.num_cols = None\n",
    "        self.num_rows = None\n",
    "        self.padded_num_cols = None\n",
    "        self.padded_num_rows = None\n",
    "        self.xlimits = None\n",
    "        self.ylimits = None\n",
    "        self.padded_xlimits = None\n",
    "        self.padded_ylimits = None\n",
    "        self.pad_width = None\n",
    "        self.res = None\n",
    "        self.pmf_grid_initialized = False\n",
    "\n",
    "        # Initialize batch_sample variables\n",
    "        self.sample_grid_batch_d = None\n",
    "        self.rng_states_d = None\n",
    "        self.device_var_initialized = False\n",
    "\n",
    "        # For visualization\n",
    "        self.cell_dimensions = None\n",
    "        self.figsize = None\n",
    "\n",
    "    def set_TDM_from_semantic_grid(self, sg, res, num_pmf_bins, bin_values, bin_values_bounds,\n",
    "                                  xlimits, ylimits, id2name, name2terrain, terrain2pmf):\n",
    "        \"\"\"\n",
    "        Save semantic grid and initialize visualization parameters.\n",
    "        initialize the PMF grid and copy to device. \n",
    "        Return: (pmf_grid, pmf_grid_d)\n",
    "        \"\"\"\n",
    "        # Based on semantics, construct the grid \n",
    "        self.semantic_grid = sg.copy()\n",
    "        self.id2name = id2name # dict[semantic_id]=>name\n",
    "        self.name2terrain = name2terrain # dict[name]=>Terrain object\n",
    "        self.id2terrain_fn = lambda semantic_id: self.name2terrain[self.id2name[semantic_id]]\n",
    "        self.terrain2pmf = terrain2pmf\n",
    "        self.semantic_grid_initialized = True\n",
    "        self.cell_dimensions = (res, res)\n",
    "        self.xlimits = xlimits\n",
    "        self.ylimits = ylimits\n",
    "        self.num_rows, self.num_cols = sg.shape\n",
    "        self.num_pmf_bins = num_pmf_bins\n",
    "        self.bin_values = np.asarray(bin_values).astype(np.float32)\n",
    "        self.bin_values_bounds = np.asarray(bin_values_bounds).astype(np.float32)\n",
    "        self.res = res\n",
    "        assert bin_values[0]==0, \"Assume minimum bin value is 0 for now\"\n",
    "        assert bin_values_bounds[0]==0, \"Assume minimum traction is 0 for now\"\n",
    "        \n",
    "\n",
    "        # Initialize pmf grid\n",
    "        # Account for padding\n",
    "        self.pmf_grid = np.zeros((self.num_pmf_bins, self.num_rows, self.num_cols), dtype=np.int8)\n",
    "        for ri in range(self.num_rows):\n",
    "            for ci in range(self.num_cols):\n",
    "                terrain = self.id2terrain_fn(self.semantic_grid[ri, ci])\n",
    "                values, pmf = self.terrain2pmf[terrain]\n",
    "                self.pmf_grid[:, ri, ci] = np.rint(pmf*100).astype(np.int8)\n",
    "                # Make sure cum sum is 100\n",
    "                self.pmf_grid[-1, ri, ci] = np.int8(100)-np.sum(self.pmf_grid[:-1, ri, ci])\n",
    "        \n",
    "        padded_pmf_grid, padded_xlimits, padded_ylimits = self.set_padding(self.pmf_grid, self.max_speed, self.dt, res,\n",
    "                                                            xlimits, ylimits)\n",
    "        self.pmf_grid_d = cuda.to_device(padded_pmf_grid)\n",
    "        self.padded_xlimits = padded_xlimits\n",
    "        self.padded_ylimits = padded_ylimits\n",
    "        _, self.padded_num_cols, self.padded_num_rows = padded_pmf_grid.shape\n",
    "        self.bin_values_d = cuda.to_device(bin_values)\n",
    "        self.bin_values_bounds_d = cuda.to_device(bin_values_bounds)\n",
    "        self.pmf_grid_initialized = True\n",
    "\n",
    "        \n",
    "    def set_TDM_from_PMF_grid(self, pmf_grid, res, xlimits, ylimits, bin_values, bin_values_bounds):\n",
    "        # TODO: make sure parameters are all set properly\n",
    "\n",
    "\n",
    "        assert len(pmf_grid.shape)==3, \"PMF grid must have 3 dimensions\"\n",
    "        self.num_pmf_bins, self.num_rows, self.num_cols = pmf_grid.shape\n",
    "        self.cell_dimensions = (res, res)\n",
    "        self.xlimits = xlimits\n",
    "        self.ylimits = ylimits\n",
    "\n",
    "        self.pmf_grid = np.asarray(pmf_grid).astype(np.int8)\n",
    "        self.bin_values = np.asarray(bin_values).astype(np.float32)\n",
    "        self.bin_values_bounds = np.asarray(bin_values_bounds).astype(np.float32)\n",
    "        assert bin_values[0]==0, \"Assume minimum bin value is 0 for now\"\n",
    "        assert bin_values_bounds[0]==0, \"Assume minimum traction is 0 for now\"\n",
    "        # self.pmf_grid_d = cuda.to_device(self.pmf_grid)\n",
    "        self.bin_values_d = cuda.to_device(bin_values)\n",
    "        self.bin_values_bounds_d = cuda.to_device(bin_values_bounds)\n",
    "        self.res = res\n",
    "\n",
    "        padded_pmf_grid, padded_xlimits, padded_ylimits = self.set_padding(self.pmf_grid, self.max_speed, self.dt, res,\n",
    "                                                            xlimits, ylimits)\n",
    "\n",
    "        self.pmf_grid_d = cuda.to_device(padded_pmf_grid)\n",
    "        self.padded_xlimits = padded_xlimits\n",
    "        self.padded_ylimits = padded_ylimits\n",
    "        _, self.padded_num_rows, self.padded_num_cols = padded_pmf_grid.shape\n",
    "        self.pmf_grid_initialized = True \n",
    "\n",
    "        \n",
    "\n",
    "    def set_padding(self, pmf_grid, max_speed, dt, res, xlimits, ylimits):\n",
    "        # Padd the nominal pmf grid with 0_traction components (assumed to be the first bin values)\n",
    "        _, original_height, original_width = pmf_grid.shape\n",
    "        self.pad_width = pad_width = int(np.ceil(max_speed*dt/res))\n",
    "        self.padded_num_cols = self.num_cols+2*pad_width\n",
    "        self.padded_num_rows = self.num_rows+2*pad_width\n",
    "        padded_xlimits = np.array([xlimits[0]-pad_width*res, xlimits[0]+pad_width*res])\n",
    "        padded_ylimits = np.array([ylimits[0]-pad_width*res, ylimits[0]+pad_width*res])\n",
    "\n",
    "        padded_pmf_grid = np.zeros((self.num_pmf_bins, original_height+int(2*pad_width), original_width+int(2*pad_width)), dtype=np.int8)\n",
    "        padded_pmf_grid[0] = 100 # Fill the probability mass associated with 0 traction\n",
    "        padded_pmf_grid[:, pad_width:(pad_width+original_height), pad_width:(pad_width+original_width)] = pmf_grid\n",
    "        \n",
    "        return padded_pmf_grid, padded_xlimits, padded_ylimits\n",
    "\n",
    "\n",
    "    def init_device_vars_before_sampling(self, seed=1):\n",
    "        # num_samples = number of grids\n",
    "        if not self.device_var_initialized:\n",
    "            _, rows, cols = self.pmf_grid_d.shape\n",
    "            self.rng_states_d = create_xoroshiro128p_states(self.TOTAL_THREADS, seed=seed)\n",
    "            self.sample_grid_batch_d = cuda.device_array((self.NUM_GRID_SAMPLES, rows, cols), dtype=np.int8)\n",
    "            self.device_var_initialized = True\n",
    "    \n",
    "    def sample_grids(self):\n",
    "        # Invoke the GPU kernels\n",
    "        self.sample_grids_numba[self.BLOCK_DIM, self.THREAD_DIM](\n",
    "            self.sample_grid_batch_d, self.pmf_grid_d, self.rng_states_d,\n",
    "            self.bin_values_d, self.bin_values_bounds_d\n",
    "        )\n",
    "        return self.sample_grid_batch_d\n",
    "\n",
    "\n",
    "    def int8_grid_to_float32(self, int8grid):\n",
    "        # int8 value between 0 and 100 represent some value within bin_values_bounds\n",
    "        ratio = np.asarray(int8grid.copy()).astype(np.float32)/100.\n",
    "        return ratio*(self.bin_values_bounds[1]-self.bin_values_bounds[0])+self.bin_values_bounds[0]\n",
    "\n",
    "    @staticmethod\n",
    "    @cuda.jit(fastmath=True)\n",
    "    def sample_grids_numba(grid_batch_d, pmf_grid_d, rng_states_d,\n",
    "                     bin_values_d, bin_values_bounds_d):\n",
    "        # Each 2D block samples a single grid\n",
    "        # Only consider a single row of block (1, num_blocks)\n",
    "        # Every thread takes care of a small section of the grid\n",
    "        # Return a reference to sampled grids on GPU\n",
    "\n",
    "        threads_x = cuda.blockDim.x # row\n",
    "        threads_y = cuda.blockDim.y # col\n",
    "        blocks_x = cuda.gridDim.x # row\n",
    "        blocks_y = cuda.gridDim.y # col\n",
    "        num_bins, grid_rows, grid_cols = pmf_grid_d.shape\n",
    "        num_col_entries_per_thread = math.ceil(grid_cols/threads_y)\n",
    "        num_rows_entries_per_thread = math.ceil(grid_rows/threads_x)\n",
    "        \n",
    "        # thread info\n",
    "        block_id = cuda.blockIdx.y#\n",
    "        tid_x = cuda.threadIdx.x # index within block\n",
    "        tid_y = cuda.threadIdx.y # index within block\n",
    "        abs_tid_x, abs_tid_y = cuda.grid(2) # absolute x, y index\n",
    "        thread_id = abs_tid_x*threads_y*blocks_y + abs_tid_y\n",
    "        # print(thread_id)\n",
    "        # cuda.syncthreads()\n",
    "\n",
    "        # Compute horizontal and vertical index range\n",
    "        ri_start = min(tid_x*num_rows_entries_per_thread, grid_rows)\n",
    "        ri_end = min(ri_start+num_rows_entries_per_thread, grid_rows)\n",
    "        ci_start = min(tid_y*num_col_entries_per_thread, grid_cols)\n",
    "        ci_end = min(ci_start+num_col_entries_per_thread, grid_cols)\n",
    "\n",
    "        traction_range = bin_values_bounds_d[1]-bin_values_bounds_d[0]\n",
    "        cum_pmf = np.int8(0)\n",
    "        sampled_cum_pmf = np.int8(8)\n",
    "        for ri in range(ri_start, ri_end):\n",
    "            for ci in range(ci_start, ci_end):\n",
    "                # Check which bin this belongs to\n",
    "                rand_num = xoroshiro128p_uniform_float32(rng_states_d, thread_id)\n",
    "                sampled_cum_pmf = rand_num*100.0\n",
    "                cum_pmf = 0\n",
    "                for bi in range(num_bins):\n",
    "                    cum_pmf += pmf_grid_d[bi, ri, ci]\n",
    "                    if sampled_cum_pmf <= cum_pmf:\n",
    "                        grid_batch_d[block_id, ri, ci] = np.int8(100.*(bin_values_d[bi]-bin_values_bounds_d[0])/traction_range)\n",
    "                        if grid_batch_d[block_id, ri, ci]<0:\n",
    "                            print(\"<0\")\n",
    "                        break\n",
    "        cuda.syncthreads()\n",
    "\n",
    "class TDM_Visualizer(object):\n",
    "\n",
    "\n",
    "    PREFERRED_MAX_FIG_WIDTH = 12\n",
    "    PREFERRED_MAX_FIG_HEIGHT = 8\n",
    "\n",
    "    def __init__(self, tdm):\n",
    "        self.semantic_grid_initialized = tdm.semantic_grid_initialized\n",
    "        self.num_rows = tdm.padded_num_rows\n",
    "        self.num_cols = tdm.padded_num_cols\n",
    "        self.ylimits = copy.deepcopy(tdm.ylimits)\n",
    "        self.xlimits = copy.deepcopy(tdm.xlimits)\n",
    "\n",
    "        self.semantic_grid = copy.deepcopy(tdm.semantic_grid)\n",
    "        self.id2name = copy.deepcopy(tdm.id2name)\n",
    "        self.name2terrain = copy.deepcopy(tdm.name2terrain)\n",
    "        self.id2terrain_fn = copy.deepcopy(tdm.id2terrain_fn)\n",
    "        self.id2rgb = {sid: self.id2terrain_fn(sid).rgb for sid in self.id2name}\n",
    "        self.terrain2pmf = copy.deepcopy(tdm.terrain2pmf)\n",
    "        self.semantic_grid_initialized = tdm.semantic_grid_initialized\n",
    "        self.cell_dimensions = copy.deepcopy(tdm.cell_dimensions)\n",
    "        self.xlimits = copy.deepcopy(tdm.padded_xlimits)\n",
    "        self.ylimits = copy.deepcopy(tdm.padded_ylimits)\n",
    "        self.num_pmf_bins = copy.deepcopy(tdm.num_pmf_bins)\n",
    "        self.bin_values = copy.deepcopy(tdm.bin_values)\n",
    "        self.bin_values_bounds = copy.deepcopy(tdm.bin_values_bounds)\n",
    "        \n",
    "        # If padded, create new semantic_grid and update color (using black?)\n",
    "        self.pad_width = tdm.pad_width\n",
    "        self.id2name[-1] = \"Padding\"\n",
    "        self.id2rgb[-1] = (0,0,0,)\n",
    "\n",
    "        original_semantic_grid = copy.deepcopy(self.semantic_grid)\n",
    "        self.semantic_grid = -1*np.ones((self.num_rows, self.num_cols))\n",
    "        self.semantic_grid[self.pad_width:(self.num_rows-self.pad_width), self.pad_width:(self.num_cols-self.pad_width)] = original_semantic_grid\n",
    "            \n",
    "\n",
    "    def draw(self, figsize=(10,10)):\n",
    "        if not self.semantic_grid_initialized:\n",
    "            print(\"Semantic grid not initialized. Cannot invoke draw() function\")\n",
    "            return\n",
    "\n",
    "        if figsize is None:\n",
    "            self.figsize = self.calc_auto_figsize(self.xlimits, self.ylimits)\n",
    "            fig, ax = self.draw_base_grid(self.figsize)\n",
    "        else:\n",
    "            fig, ax = self.draw_base_grid(figsize)\n",
    "\n",
    "        if self.semantic_grid_initialized:\n",
    "            self.draw_semantic_patches(ax)\n",
    "        else:\n",
    "            print(\"Colors not shown as semantic grid is not initialized.\")\n",
    "        return fig, ax\n",
    "    \n",
    "    def draw_base_grid(self, figsize):\n",
    "        cols, rows = self.num_cols, self.num_rows\n",
    "        minx, maxx = self.xlimits\n",
    "        miny, maxy = self.ylimits\n",
    "\n",
    "        width, height = self.cell_dimensions\n",
    "\n",
    "        x = list(map(lambda i: minx + width*i, range(cols+1)))\n",
    "        y = list(map(lambda i: miny + height*i, range(rows+1)))\n",
    "\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "\n",
    "        hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "        vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "        lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "        line_collection = LineCollection(lines, color=\"black\", linewidths=0.5)\n",
    "        ax = plt.gca()\n",
    "        ax.add_collection(line_collection)\n",
    "        ax.set_xlim(x[0]-1, x[-1]+1)\n",
    "        ax.set_ylim(y[0]-1, y[-1]+1)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.axis('off')\n",
    "\n",
    "        return fig, plt.gca()\n",
    "\n",
    "    def calc_auto_figsize(self, xlimits, ylimits):\n",
    "        (minx, maxx) = xlimits\n",
    "        (miny, maxy) = ylimits\n",
    "        width, height = maxx - minx, maxy - miny\n",
    "        if width > height:\n",
    "            figsize = (self.PREFERRED_MAX_FIG_WIDTH, height * self.PREFERRED_MAX_FIG_WIDTH / width)\n",
    "        else:\n",
    "            figsize = (width * self.PREFERRED_MAX_FIG_HEIGHT / height, self.PREFERRED_MAX_FIG_HEIGHT)\n",
    "        return figsize\n",
    "\n",
    "    def cell_verts(self, ix, iy):\n",
    "        width, height = self.cell_dimensions\n",
    "        x, y = self.cell_xy(ix, iy)\n",
    "        verts = [(x + ofx*0.5*width, y + ofy*0.5*height) for ofx, ofy in [(-1,-1),(-1,1),(1,1),(1,-1)]]\n",
    "        return verts\n",
    "\n",
    "    def cell_xy(self, ix, iy):\n",
    "        \"\"\"Returns the center xy point of the cell.\"\"\"\n",
    "        minx, maxx = self.xlimits\n",
    "        miny, maxy = self.ylimits\n",
    "        width, height = self.cell_dimensions\n",
    "        return minx + (ix+0.5) * width, miny + (iy+0.5) * height\n",
    "\n",
    "    def draw_semantic_patches(self, ax):\n",
    "        collection_recs = PolyCollection(self.get_all_cell_verts(), facecolors=self.get_terrain_rgbs())\n",
    "        ax.add_collection(collection_recs)\n",
    "        \n",
    "    def get_all_cell_verts(self):\n",
    "        num_rows, num_cols = self.semantic_grid.shape\n",
    "        return [self.cell_verts(ix, iy) for iy in range(num_rows) for ix in range(num_cols) ]\n",
    "    \n",
    "    def get_terrain_rgbs(self):\n",
    "        return [self.id2rgb[sid] for sid in self.semantic_grid.reshape(-1)]\n",
    "    \n",
    "\n",
    "\n",
    "# A deterministic grid with traction coefficients (can be generated by SDM)\n",
    "class TractionGrid(object):\n",
    "    def __init__(self, lin_traction, ang_traction, res=1.0, use_int8=False):\n",
    "        if use_int8:\n",
    "          # Use int 0-100 to represent values between 0 and 1\n",
    "          self.lin_traction = (100*lin_traction).astype(np.int8)\n",
    "          self.ang_traction = (100*ang_traction).astype(np.int8)\n",
    "        else:\n",
    "          self.lin_traction = lin_traction\n",
    "          self.ang_traction = ang_traction\n",
    "        self.res = res\n",
    "        self.height, self.width = self.lin_traction.shape\n",
    "        self.xlimits = (0, self.res*self.width)\n",
    "        self.ylimits = (0, self.res*self.height)\n",
    "        \n",
    "\n",
    "    def get(self, x,y):\n",
    "        # If within bounds, return queried value. Otherwise, return 0\n",
    "        xi = int((x-self.xlimits[0])//self.res)\n",
    "        yi = int((y-self.ylimits[0])//self.res)\n",
    "        # print(yi, xi)\n",
    "        if (xi<0) or (xi>=self.width) or (yi<0) or (yi>=self.height):\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return self.lin_traction[yi, xi], self.ang_traction[yi, xi]\n",
    "    \n",
    "    def get_grids(self):\n",
    "        return self.lin_traction, self.ang_traction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentile of the speed distribution to compute conditional expectation?\n",
    "cvar_alpha =0.3\n",
    "\n",
    "pmf_bounds = [0, 1.0]\n",
    "bush_lin_gm = GaussianMixture(sample_bounds=[0,.8], pmf_bounds=pmf_bounds, weights=[0.5, 0.5], means=[0.1, 0.6], stds=[0.1, 0.1])\n",
    "bush_ang_gm = GaussianMixture(sample_bounds=[0,.3], pmf_bounds=pmf_bounds, weights=[0.5, 0.5], means=[0.1, 0.6], stds=[0.1, 0.1])\n",
    "dirt_lin_gm = GaussianMixture(sample_bounds=[0, 1.0], pmf_bounds=pmf_bounds, weights=[1], means=[0.8], stds=[0.1])\n",
    "dirt_ang_gm = GaussianMixture(sample_bounds=[0, 1.0], pmf_bounds=pmf_bounds, weights=[1], means=[0.8], stds=[0.1])\n",
    "\n",
    "bush = Terrain(name='Vegetation', lin_density=bush_lin_gm, ang_density=bush_ang_gm, cvar_alpha=cvar_alpha, rgb=np.array((0,250,0))/255.0)\n",
    "dirt = Terrain(name='Dirt', lin_density=dirt_lin_gm, ang_density=dirt_ang_gm, cvar_alpha=cvar_alpha, rgb=np.array((200,190,160))/255.0)\n",
    "print(bush)\n",
    "print(dirt)\n",
    "\n",
    "ID2NAME = {\n",
    "    0: dirt.name,\n",
    "    1: bush.name\n",
    "}\n",
    "NAME2TERRAIN = {\n",
    "    bush.name: bush,\n",
    "    dirt.name: dirt\n",
    "}\n",
    "\n",
    "num_bins=10\n",
    "b_lin_values, b_lin_pmf = bush_lin_gm.get_pmf(num_bins=num_bins)\n",
    "b_ang_values, b_ang_pmf = bush_ang_gm.get_pmf(num_bins=num_bins)\n",
    "d_lin_values, d_lin_pmf = dirt_lin_gm.get_pmf(num_bins=num_bins)\n",
    "d_ang_values, d_ang_pmf = dirt_ang_gm.get_pmf(num_bins=num_bins)\n",
    "LIN_TERRAIN2PMG = {\n",
    "    bush: (b_lin_values, b_lin_pmf),\n",
    "    dirt: (d_lin_values, d_lin_pmf),\n",
    "}\n",
    "ANG_TERRAIN2PMG = {\n",
    "    bush: (b_ang_values, b_ang_pmf),\n",
    "    dirt: (d_ang_values, d_ang_pmf),\n",
    "}\n",
    "\n",
    "# semantic_grid = np.array(\n",
    "#     [\n",
    "#         [0,0,0,0,0,0,0,0,0,0],\n",
    "#         [0,0,0,0,1,0,0,0,0,0],\n",
    "#         [0,0,0,1,1,1,0,0,0,0],\n",
    "#         [0,0,0,1,1,1,1,0,0,0],\n",
    "#         [0,0,0,1,1,1,1,0,0,0],\n",
    "#         [0,0,0,1,1,1,1,0,0,0],\n",
    "#         [0,0,0,1,1,1,1,0,0,0],\n",
    "#         [0,0,0,1,1,1,0,0,0,0],\n",
    "#         [0,0,0,0,0,0,0,0,0,0],\n",
    "#         [0,0,0,0,0,0,0,0,0,0]\n",
    "#     ]\n",
    "# )\n",
    "# semantic_grid = np.zeros((100, 100), dtype=np.int8)\n",
    "# rand_num = np.random.rand(100, 100)\n",
    "semantic_grid = np.zeros((40, 40), dtype=np.int8)\n",
    "rand_num = np.random.rand(40, 40)\n",
    "semantic_grid[rand_num>=0.2] = 0\n",
    "semantic_grid[rand_num<0.2] = 1\n",
    "\n",
    "# Assume bin values are the same for linear and angular components for now\n",
    "res = 1.0\n",
    "xlimits = (0,semantic_grid.shape[1]*res)\n",
    "ylimits = (0,semantic_grid.shape[0]*res)\n",
    "num_pmf_bins = len(d_ang_pmf)\n",
    "bin_values = b_lin_values\n",
    "bin_values_bounds = (np.min(b_lin_values), np.max(b_lin_values))\n",
    "\n",
    "# # ------------- Create and visualize the map ------------\n",
    "max_speed = 5.0\n",
    "dt=0.1\n",
    "lin_tdm = TDM_Numba(max_speed=max_speed, dt=dt)\n",
    "ang_tdm = TDM_Numba(max_speed=max_speed, dt=dt)\n",
    "lin_tdm.set_TDM_from_semantic_grid(semantic_grid, res, num_pmf_bins, bin_values, bin_values_bounds, \n",
    "                    xlimits, ylimits, ID2NAME, NAME2TERRAIN, LIN_TERRAIN2PMG)\n",
    "ang_tdm.set_TDM_from_semantic_grid(semantic_grid, res, num_pmf_bins, bin_values, bin_values_bounds, \n",
    "                    xlimits, ylimits, ID2NAME, NAME2TERRAIN, ANG_TERRAIN2PMG)\n",
    "\n",
    "\n",
    "lin_tdm_vis = TDM_Visualizer(lin_tdm)\n",
    "fig, ax = lin_tdm_vis.draw(figsize=(5, 5))\n",
    "# ax.set_title(\"Terrain\")\n",
    "\n",
    "# -------------- Visualize the speed distribution for each class---------\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "vis_density(axes[0], bush_lin_gm, bush, vis_cvar_alpha=cvar_alpha, title=\"Veg (lin. traction)\", color=bush.rgb)\n",
    "vis_density(axes[1], bush_ang_gm, bush, vis_cvar_alpha=cvar_alpha, title=\"Veg (ang. traction)\", color=bush.rgb)\n",
    "vis_density(axes[2], dirt_lin_gm, dirt, vis_cvar_alpha=cvar_alpha, title=\"Dirt (lin. traction)\", color=dirt.rgb)\n",
    "vis_density(axes[3], dirt_ang_gm, dirt, vis_cvar_alpha=cvar_alpha, title=\"Dirt (ang. traction)\", color=dirt.rgb)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "vis_density_as_pmf(axes[0], bush_lin_gm, bush, num_bins=10, title=\"Veg (lin. traction)\", color=bush.rgb)\n",
    "vis_density_as_pmf(axes[1], bush_ang_gm, bush, num_bins=10, title=\"Veg (ang. traction)\", color=bush.rgb)\n",
    "vis_density_as_pmf(axes[2], dirt_lin_gm, dirt, num_bins=10, title=\"Dirt (lin. traction)\", color=dirt.rgb)\n",
    "vis_density_as_pmf(axes[3], dirt_ang_gm, dirt, num_bins=10, title=\"Dirt (ang. traction)\", color=dirt.rgb)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# lin, ang = lin_tdm.get_sample_grid().get_grids()\n",
    "# fig,axes = plt.subplots(1,2)\n",
    "# img = axes[0].imshow(lin, origin='lower', vmin=0, vmax=1.0, cmap='gray')\n",
    "# axes[0].set_title('linear traction')\n",
    "# img = axes[1].imshow(ang, origin='lower', vmin=0, vmax=1.0, cmap='gray')\n",
    "# axes[1].set_title('angular traction')\n",
    "# # add space for colour bar\n",
    "# fig.subplots_adjust(right=0.85)\n",
    "# cbar_ax = fig.add_axes([0.88, 0.15, 0.04, 0.7])\n",
    "# fig.colorbar(img, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "lin_tdm.init_device_vars_before_sampling()\n",
    "ang_tdm.init_device_vars_before_sampling()\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "lin_sample_grid_batch_d = lin_tdm.sample_grids()\n",
    "ang_sample_grid_batch_d = ang_tdm.sample_grids()\n",
    "print(\"Sampling took {}s\".format(time.time()-t0))\n",
    "t0 = time.time()\n",
    "lin_sampled = lin_sample_grid_batch_d.copy_to_host()\n",
    "ang_sampled = ang_sample_grid_batch_d.copy_to_host()\n",
    "print(\"Copying took {}s\".format(time.time()-t0))\n",
    "\n",
    "grid_samples = lin_tdm.int8_grid_to_float32(lin_sampled)\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(grid_samples[11], origin='lower', vmin=np.min(grid_samples), vmax=np.max(grid_samples), cmap='gray')\n",
    "ax.set_title('sampled linear traction')\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.88, 0.15, 0.04, 0.7])\n",
    "fig.colorbar(img, cax=cbar_ax)\n",
    "plt.show()\n",
    "\n",
    "grid_samples = ang_tdm.int8_grid_to_float32(ang_sampled)\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(grid_samples[1000], origin='lower', vmin=np.min(grid_samples), vmax=np.max(grid_samples), cmap='gray')\n",
    "ax.set_title('sampled angular traction')\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.88, 0.15, 0.04, 0.7])\n",
    "fig.colorbar(img, cax=cbar_ax)\n",
    "plt.show()\n",
    "\n",
    "# Sanity checks\n",
    "assert np.sum(lin_sampled<0)==0\n",
    "assert np.sum(ang_sampled<0)==0\n",
    "assert len(lin_sampled[lin_sampled<0]) == 0\n",
    "assert len(ang_sampled[ang_sampled<0]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Numba RNG for Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kernel(cfg, mean, std):\n",
    "  rng_states = create_xoroshiro128p_states(cfg.num_blocks*cfg.num_threads, seed=1)\n",
    "  results_d = cuda.device_array((cfg.num_blocks*cfg.num_threads), dtype=np.float32)\n",
    "  numba_sample_gaussian[cfg.num_blocks, cfg.num_threads](rng_states, mean, std, results_d)  \n",
    "  return results_d.copy_to_host()\n",
    "\n",
    "# Each block works together to create the HxW random array, casted to 0~100 int8\n",
    "@cuda.jit\n",
    "def numba_sample_gaussian(rng_states, mean, std, results):\n",
    "  # How many rows and columns should each thread take care of?\n",
    "  thread_id = cuda.grid(1)\n",
    "  results[thread_id] = mean + std*xoroshiro128p_normal_float32(rng_states, thread_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we pass config to the function and build kernel?\n",
    "class Config:\n",
    "  def __init__(self, num_threads=1000, num_blocks=None):\n",
    "    # Some computations are ok as long as compiler can infer the type\n",
    "    if num_blocks is None:\n",
    "      self.num_blocks = int(num_threads/3)*100\n",
    "      self.num_blocks = min(10000, self.num_blocks)\n",
    "    else:\n",
    "      self.num_blocks = int(num_threads/num_blocks)*100\n",
    "    self.num_threads=num_threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples have mean=1.0000311136245728 and std=0.9995415806770325\n"
     ]
    }
   ],
   "source": [
    "# It's possible to reuse this state multiple times\n",
    "cfg = Config(100)\n",
    "results = run_kernel(cfg, mean=1.0, std=1.0)\n",
    "plt.hist(results, bins=100)\n",
    "plt.show()\n",
    "print(\"Samples have mean={} and std={}\".format(results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get dynamically allocated shared variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/sara/phoenix-r1/venv/lib/python3.8/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "shape of shared memory should match the block size 10 10\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[0]= 1.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n",
      "sm[1]= 0.000000\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def myKernel():\n",
    "   sm = cuda.shared.array(shape=0,dtype=numba.float32)\n",
    "   sm[0] = 1\n",
    "   # do stuff\n",
    "   print(\"shape of shared memory should match the block size\", sm.shape[0], cuda.blockDim.x)\n",
    "   print(\"sm[0]=\", sm[0])\n",
    "   print(\"sm[1]=\", sm[1])\n",
    "   \n",
    "\n",
    "grid = 1\n",
    "block = 10\n",
    "stream = 0\n",
    "sm_size = block*np.float32().itemsize\n",
    "print(\"sm_size = {}\".format(sm_size))\n",
    "# myKernel[grid,block,stream,sm_size](arga)\n",
    "myKernel[grid,block,stream,sm_size]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now clean up MPPI_Numba\n",
    "* Preinitialize GPU variables (map samples, noise_samples, useq0)\n",
    "* Take a reference to the TDM_Numba object\n",
    "* Allow optimization steps performed on GPU as well (avoid copying back and forth)\n",
    "* Optionally get the solution (and/or samples) from GPU and visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T= 10\n",
    "dt=0.1\n",
    "TIMESTEPS = timesteps=int(T/dt)\n",
    "num_control_rollouts = 1024\n",
    "\n",
    "class MPPI_Numba(object):\n",
    "\n",
    "  NUM_CONTROL_ROLLOUTS = num_control_rollouts\n",
    "  NUM_STEPS = TIMESTEPS\n",
    "  NUM_GRID_SAMPLES = num_grid_samples\n",
    "\n",
    "\n",
    "  def __init__(self):\n",
    "    self.params = None\n",
    "    self.params_set = False\n",
    "\n",
    "    # Hold reference to the current linear and angular TDM\n",
    "    self.lin_tdm = None\n",
    "    self.ang_tdm = None\n",
    "    self.tdm_set = False\n",
    "\n",
    "    # Initialize device variables\n",
    "    self.noise_samples_d = None\n",
    "    self.u_cur_d = None\n",
    "    self.costs_d = None\n",
    "    self.weights_d = None\n",
    "    self.rng_states_d = None\n",
    "    \n",
    "    self.device_var_initialized = False\n",
    "\n",
    "    # Sanity checks\n",
    "    assert self.NUM_STEPS <= 1024, \"NUM_STEPS={} current cannot be more than 1024\".format(self.NUM_STEPS)\n",
    "\n",
    "\n",
    "  def is_within_bound(self, v, vbounds):\n",
    "    return v>=vbounds[0] and v<=vbounds[1]\n",
    "\n",
    "  def set_params(self, params):\n",
    "    # Check conditions\n",
    "    assert self.tdm_set, \"TDM must be set before MPPI parameters\"\n",
    "    # angle must be 0~2*np.pi\n",
    "    assert self.is_within_bound(params['x0'][0], self.lin_tdm.xlimits), \"x0[0] is not within xlimits.\"\n",
    "    assert self.is_within_bound(params['x0'][1], self.lin_tdm.ylimits), \"x0[1] is not within ylimits.\"\n",
    "    # assert self.is_within_bound(params['x0'][2], [0, 2*np.pi]), \"x0[2] is not in [0,2*pi]\"\n",
    "\n",
    "    self.params = params\n",
    "    self.params_set = True\n",
    "\n",
    "  def update_params(self, sub_params):\n",
    "    # Update a subset of the parameters (e.g., x0, xgoal)\n",
    "    for key, val in sub_params.items():\n",
    "      if key in self.params:\n",
    "        self.params[key] = val\n",
    "\n",
    "  def set_tdm(self, lin_tdm, ang_tdm):\n",
    "    self.lin_tdm = lin_tdm\n",
    "    self.ang_tdm = ang_tdm\n",
    "    self.tdm_set = True\n",
    "\n",
    "\n",
    "  def init_device_vars_before_solving(self):\n",
    "    # noise, sol, \n",
    "    if not self.params_set:\n",
    "      assert False, \"Params not set. Cannot initialize GPU memory for noise samples and current control sequence.\"\n",
    "\n",
    "    if not self.device_var_initialized:\n",
    "      self.noise_samples_d = cuda.device_array((self.NUM_CONTROL_ROLLOUTS, self.NUM_STEPS, 2), dtype=np.float32) # to be sampled collaboratively via GPU\n",
    "      self.costs_d = cuda.device_array((self.NUM_CONTROL_ROLLOUTS), dtype=np.float32)\n",
    "      self.weights_d = cuda.device_array((self.NUM_CONTROL_ROLLOUTS), dtype=np.float32)\n",
    "      self.rng_states_d = create_xoroshiro128p_states(self.NUM_CONTROL_ROLLOUTS*self.NUM_STEPS, seed=1)\n",
    "      self.u_cur_d = cuda.to_device(np.asarray(self.params['u_seq0']).astype(np.float32)) # likely reused\n",
    "      self.device_var_initialized = True\n",
    "\n",
    "  def solve(self):\n",
    "    assert self.params_set, \"MPPI parameters are not set\"\n",
    "    assert self.tdm_set, \"MPPI has not received TDMs\"\n",
    "\n",
    "    if not self.device_var_initialized:\n",
    "      print(\"Device variables not initialized. Cannot run mppi.\")\n",
    "      return\n",
    "    \n",
    "    # Move things to GPU\n",
    "    res_d = np.float32(self.lin_tdm.res) # no need to move int\n",
    "    xlimits_d = cuda.to_device(self.lin_tdm.padded_xlimits.astype(np.float32))\n",
    "    ylimits_d = cuda.to_device(self.lin_tdm.padded_ylimits.astype(np.float32))\n",
    "    vrange_d = cuda.to_device(self.params['vrange'].astype(np.float32))\n",
    "    wrange_d = cuda.to_device(self.params['wrange'].astype(np.float32))\n",
    "    xgoal_d = cuda.to_device(self.params['xgoal'].astype(np.float32))\n",
    "    v_post_rollout_d = np.float32(self.params['v_post_rollout'])\n",
    "    goal_tolerance_d = np.float32(self.params['goal_tolerance'])\n",
    "    lambda_weight_d = np.float32(self.params['lambda_weight'])\n",
    "    u_std_d = cuda.to_device(self.params['u_std'].astype(np.float32))\n",
    "    cvar_alpha_d = np.float32(self.params['cvar_alpha'])\n",
    "    x0_d = cuda.to_device(self.params['x0'].astype(np.float32))\n",
    "    dt_d = np.float32(self.params['dt'])\n",
    "    \n",
    "    \n",
    "    # Sample environment realizations for estimating cvar\n",
    "    self.lin_tdm.init_device_vars_before_sampling()\n",
    "    self.ang_tdm.init_device_vars_before_sampling()\n",
    "    lin_sample_grid_batch_d = self.lin_tdm.sample_grids() # get ref to device samples\n",
    "    ang_sample_grid_batch_d = self.ang_tdm.sample_grids() # get ref to device samples\n",
    "\n",
    "    # Optimization loop\n",
    "    for k in range(self.params['num_opt']):\n",
    "      # Sample control noise\n",
    "      self.sample_noise_numba[self.NUM_CONTROL_ROLLOUTS, self.NUM_STEPS](\n",
    "            self.rng_states_d, u_std_d, self.noise_samples_d)\n",
    "      \n",
    "      # Rollout and compute mean or cvar\n",
    "      self.rollout_numba[self.NUM_CONTROL_ROLLOUTS, self.NUM_GRID_SAMPLES](\n",
    "        lin_sample_grid_batch_d,\n",
    "        ang_sample_grid_batch_d,\n",
    "        self.lin_tdm.bin_values_bounds_d,\n",
    "        self.ang_tdm.bin_values_bounds_d,\n",
    "        res_d,\n",
    "        xlimits_d,\n",
    "        ylimits_d,\n",
    "        vrange_d,\n",
    "        wrange_d,\n",
    "        xgoal_d,\n",
    "        v_post_rollout_d,\n",
    "        goal_tolerance_d,\n",
    "        lambda_weight_d,\n",
    "        u_std_d,\n",
    "        cvar_alpha_d,\n",
    "        x0_d,\n",
    "        dt_d,\n",
    "        self.noise_samples_d,\n",
    "        self.u_cur_d,\n",
    "        # results\n",
    "        self.costs_d\n",
    "      )\n",
    "\n",
    "      # Compute cost and update the optimal control on device\n",
    "      self.update_useq_numba[1, 32](\n",
    "        lambda_weight_d, \n",
    "        self.costs_d, \n",
    "        self.noise_samples_d, \n",
    "        self.weights_d, \n",
    "        vrange_d,\n",
    "        wrange_d,\n",
    "        self.u_cur_d\n",
    "      )\n",
    "\n",
    "    # return: full control sequence copied from GPU\n",
    "    return self.u_cur_d.copy_to_host()\n",
    "\n",
    "  def update_state(self, new_x0, num_steps=1):\n",
    "    # Shift solver state forward in time\n",
    "    # Set the current starting position\n",
    "    # Set the current map based on the pmf?\n",
    "    # Should be done on GPU\n",
    "    # Update current sequence of control, \n",
    "    pass\n",
    "\n",
    "\n",
    "  \"\"\"GPU kernels\"\"\"\n",
    "\n",
    "  @staticmethod\n",
    "  @cuda.jit(fastmath=True)\n",
    "  def rollout_numba(\n",
    "          lin_sample_grid_batch_d,\n",
    "          ang_sample_grid_batch_d,\n",
    "          lin_bin_values_bounds_d,\n",
    "          ang_bin_values_bounds_d,\n",
    "          res_d, \n",
    "          xlimits_d, \n",
    "          ylimits_d, \n",
    "          vrange_d, \n",
    "          wrange_d, \n",
    "          xgoal_d, \n",
    "          v_post_rollout_d, \n",
    "          goal_tolerance_d, \n",
    "          lambda_weight_d, \n",
    "          u_std_d, \n",
    "          cvar_alpha_d, \n",
    "          x0_d, \n",
    "          dt_d,\n",
    "          noise_samples_d,\n",
    "          u_cur_d,\n",
    "          costs_d):\n",
    "    \"\"\"\n",
    "    Every thread in each block considers different traction grids but the same control sequence.\n",
    "    Each block produces a single result (reduce a shared list to produce CVaR or mean. Is there a more efficient way to do this?)\n",
    "    \"\"\"\n",
    "    # Get block id and thread id\n",
    "    bid = cuda.blockIdx.x   # index of block\n",
    "    tid = cuda.threadIdx.x  # index of thread within a block\n",
    "\n",
    "    # Create shared array for saving temporary costs\n",
    "    block_width = cuda.blockDim.x\n",
    "    thread_cost_shared = cuda.shared.array(num_grid_samples, dtype=numba.float32)\n",
    "    thread_cost_shared[tid] = 0.0\n",
    "\n",
    "    # Move control sequence to shared array as well\n",
    "    timesteps = len(u_cur_d)\n",
    "    useq_shared = cuda.shared.array((TIMESTEPS, 2), dtype=numba.float32) # can only initialize using constants..\n",
    "    noise_shared = cuda.shared.array((TIMESTEPS, 2), dtype=numba.float32) # can only initialize using constants..\n",
    "    \n",
    "    # Since each thread uses the same sequence, construct in shared memory\n",
    "    num = math.ceil(timesteps/block_width)\n",
    "    tstart = min(tid*num, timesteps)\n",
    "    tend = min(tstart+num, timesteps)\n",
    "    for i in range(tstart, tend):\n",
    "      useq_shared[i,0] = u_cur_d[i,0]\n",
    "      useq_shared[i,1] = u_cur_d[i,1]\n",
    "      noise_shared[i,0] = noise_samples_d[bid, i,0]\n",
    "      noise_shared[i,1] = noise_samples_d[bid, i,1]\n",
    "    \n",
    "    # Sync before moving on\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Explicit unicycle update and map lookup\n",
    "    # From here on we assume grid is properly padded so map lookup remains valid\n",
    "    height, width = lin_sample_grid_batch_d[tid].shape\n",
    "    x_curr = cuda.local.array(3, numba.float32)\n",
    "    for i in range(3): \n",
    "      x_curr[i] = x0_d[i]\n",
    "\n",
    "    goal_reached = False\n",
    "    goal_tolerance_d2 = goal_tolerance_d*goal_tolerance_d\n",
    "    dist_to_goal2 = 1e9\n",
    "    v_nom =v_noisy = w_nom = w_noisy = 0.0\n",
    "\n",
    "    lin_ratio = 0.01*(lin_bin_values_bounds_d[1]-lin_bin_values_bounds_d[0])\n",
    "    ang_ratio = 0.01*(ang_bin_values_bounds_d[1]-ang_bin_values_bounds_d[0])\n",
    "\n",
    "    PI2 = numba.float32(math.pi*2.0)\n",
    "    \n",
    "    for t in range(timesteps):\n",
    "      # Look up the traction parameters from map\n",
    "      xi = numba.int32((x_curr[0]-xlimits_d[0])//res_d)\n",
    "      yi = numba.int32((x_curr[1]-ylimits_d[0])//res_d)\n",
    "\n",
    "      vtraction = lin_bin_values_bounds_d[0] + lin_ratio*lin_sample_grid_batch_d[tid, yi, xi]\n",
    "      wtraction = ang_bin_values_bounds_d[0] + ang_ratio*ang_sample_grid_batch_d[tid, yi, xi]\n",
    "\n",
    "      # Nominal noisy control\n",
    "      v_nom = useq_shared[t, 0] + noise_shared[t, 0]\n",
    "      w_nom = useq_shared[t, 1] + noise_shared[t, 1]\n",
    "      v_noisy = max(vrange_d[0], min(vrange_d[1], v_nom))\n",
    "      w_noisy = max(wrange_d[0], min(wrange_d[1], w_nom))\n",
    "      \n",
    "      # Forward simulate\n",
    "      x_curr[0] += dt*vtraction*v_noisy*math.cos(x_curr[2])\n",
    "      x_curr[1] += dt*vtraction*v_noisy*math.sin(x_curr[2])\n",
    "      x_curr[2] += dt*wtraction*w_noisy\n",
    "\n",
    "      # Clip angle values within [0, 2pi] (Hmm don't think is needed)\n",
    "      # x_curr[2] = math.fmod(math.fmod(x_curr[2], PI2)+PI2, PI2)\n",
    "\n",
    "      # Accumulate cost starting at the initial state\n",
    "      thread_cost_shared[tid]+=dt\n",
    "      if not goal_reached:\n",
    "        dist_to_goal2 = (xgoal_d[0]-x_curr[0])**2 + (xgoal_d[1]-x_curr[1])**2\n",
    "        if dist_to_goal2<= goal_tolerance_d2:\n",
    "          goal_reached = True\n",
    "          break\n",
    "      \n",
    "    # Accumulate terminal cost \n",
    "    if not goal_reached:\n",
    "      thread_cost_shared[tid] += math.sqrt(dist_to_goal2)/v_post_rollout_d\n",
    "\n",
    "    # Accumulate the missing stage cost\n",
    "    for t in range(timesteps):\n",
    "      thread_cost_shared[tid] += lambda_weight_d*(\n",
    "              (useq_shared[t,0]/(u_std_d[0]**2))*noise_shared[t,0] + (useq_shared[t,1]/(u_std_d[1]**2))*noise_shared[t, 1])\n",
    "\n",
    "    # Reudce thread_cost_shared to a single value (mean or CVaR)\n",
    "    cuda.syncthreads()  # make sure all threads have produced costs\n",
    "\n",
    "    numel = block_width\n",
    "    if cvar_alpha_d<1:\n",
    "      numel = math.ceil(block_width*cvar_alpha_d)\n",
    "      # --- CVaR requires sorting the elements ---\n",
    "      # First sort the costs from descending order via parallel bubble sort\n",
    "      # https://stackoverflow.com/questions/42620649/sorting-algorithm-with-cuda-inside-or-outside-kernels\n",
    "      for i in range(math.ceil(block_width/2)):\n",
    "        # Odd\n",
    "        if (tid%2==0) and ((tid+1)!=block_width):\n",
    "          if thread_cost_shared[tid+1]>thread_cost_shared[tid]:\n",
    "            # swap\n",
    "            temp = thread_cost_shared[tid]\n",
    "            thread_cost_shared[tid] = thread_cost_shared[tid+1]\n",
    "            thread_cost_shared[tid+1] = temp\n",
    "        cuda.syncthreads()\n",
    "        # Even\n",
    "        if (tid%2==1) and ((tid+1)!=block_width):\n",
    "          if thread_cost_shared[tid+1]>thread_cost_shared[tid]:\n",
    "            # swap\n",
    "            temp = thread_cost_shared[tid]\n",
    "            thread_cost_shared[tid] = thread_cost_shared[tid+1]\n",
    "            thread_cost_shared[tid+1] = temp\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    # Average reduction based on quantile (all elements for cvar_alpha_d==1)\n",
    "    # The mean of the first alpha% will be the CVaR\n",
    "    numel = math.ceil(block_width*cvar_alpha_d)\n",
    "    s = 1\n",
    "    while s < numel:\n",
    "      if (tid % (2 * s) == 0) and ((tid + s) < numel):\n",
    "        # Stride by `s` and add\n",
    "        thread_cost_shared[tid] += thread_cost_shared[tid + s]\n",
    "      s *= 2\n",
    "      cuda.syncthreads()\n",
    "\n",
    "    # After the loop, the zeroth  element contains the sum\n",
    "    if tid == 0:\n",
    "      costs_d[bid] = thread_cost_shared[0]/numel\n",
    "\n",
    "  @staticmethod\n",
    "  @cuda.jit(fastmath=True)\n",
    "  def update_useq_numba(\n",
    "        lambda_weight_d,\n",
    "        costs_d,\n",
    "        noise_samples_d,\n",
    "        weights_d,\n",
    "        vrange_d,\n",
    "        wrange_d,\n",
    "        u_cur_d):\n",
    "    # Assume the function is invoked as update_useq_numba[1, NUM_THREADS]\n",
    "    tid = cuda.threadIdx.x\n",
    "    num_threads = cuda.blockDim.x\n",
    "    numel = len(noise_samples_d)\n",
    "    gap = int(math.ceil(numel / num_threads))\n",
    "\n",
    "    # Find the minimum value via reduction\n",
    "    starti = min(tid*gap, numel)\n",
    "    endi = min(starti+gap, numel)\n",
    "    if starti<numel:\n",
    "      weights_d[starti] = costs_d[starti]\n",
    "    for i in range(starti, endi):\n",
    "      weights_d[starti] = min(weights_d[starti], costs_d[i])\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    s = gap\n",
    "    while s < numel:\n",
    "      if (starti % (2 * s) == 0) and ((starti + s) < numel):\n",
    "        # Stride by `s` and add\n",
    "        weights_d[starti] = min(weights_d[starti], weights_d[starti + s])\n",
    "      s *= 2\n",
    "      cuda.syncthreads()\n",
    "\n",
    "    beta = weights_d[0]\n",
    "    \n",
    "    # Compute weight\n",
    "    for i in range(starti, endi):\n",
    "      weights_d[i] = math.exp(-1./lambda_weight_d*(costs_d[i]-beta))\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Normalize\n",
    "    # Reuse costs_d array\n",
    "    for i in range(starti, endi):\n",
    "      costs_d[i] = weights_d[i]\n",
    "    cuda.syncthreads()\n",
    "    for i in range(starti+1, endi):\n",
    "      costs_d[starti] += costs_d[i]\n",
    "    cuda.syncthreads()\n",
    "    s = gap\n",
    "    while s < numel:\n",
    "      if (starti % (2 * s) == 0) and ((starti + s) < numel):\n",
    "        # Stride by `s` and add\n",
    "        costs_d[starti] += costs_d[starti + s]\n",
    "      s *= 2\n",
    "      cuda.syncthreads()\n",
    "\n",
    "    for i in range(starti, endi):\n",
    "      weights_d[i] /= costs_d[0]\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # update the u_cur_d\n",
    "    timesteps = len(u_cur_d)\n",
    "    for t in range(timesteps):\n",
    "      for i in range(starti, endi):\n",
    "        cuda.atomic.add(u_cur_d, (t, 0), weights_d[i]*noise_samples_d[i, t, 0])\n",
    "        cuda.atomic.add(u_cur_d, (t, 1), weights_d[i]*noise_samples_d[i, t, 1])\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Blocks crop the control together\n",
    "    tgap = int(math.ceil(timesteps / num_threads))\n",
    "    starti = min(tid*tgap, timesteps)\n",
    "    endi = min(starti+tgap, timesteps)\n",
    "    for ti in range(starti, endi):\n",
    "      u_cur_d[ti, 0] = max(vrange_d[0], min(vrange_d[1], u_cur_d[ti, 0]))\n",
    "      u_cur_d[ti, 1] = max(wrange_d[0], min(wrange_d[1], u_cur_d[ti, 1]))\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  @cuda.jit(fastmath=True)\n",
    "  def update_state_numba():\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "  @staticmethod\n",
    "  @cuda.jit(fastmath=True)\n",
    "  def sample_noise_numba(rng_states, u_std_d, noise_samples_d):\n",
    "    # sample_noise_numba[NUM_U_SAMPLES, NUM_THREADS]\n",
    "    # noise_samples_d.shape is assumed to be (num_rollouts, time_steps, 2)\n",
    "    # Assume each thread corresponds to one time step\n",
    "    # For consistency, each block samples a sequence, and threads (not too many) work together over num_steps\n",
    "    block_id = cuda.blockIdx.x\n",
    "    thread_id = cuda.threadIdx.x\n",
    "    abs_thread_id = cuda.grid(1)\n",
    "\n",
    "    noise_samples_d[block_id, thread_id, 0] = u_std_d[0]*xoroshiro128p_normal_float32(rng_states, abs_thread_id)\n",
    "    noise_samples_d[block_id, thread_id, 1] = u_std_d[1]*xoroshiro128p_normal_float32(rng_states, abs_thread_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u_seq0 = np.zeros((timesteps, 2), dtype=float)\n",
    "x0=np.array([0.5, 1.5, 0])\n",
    "# xgoal= np.array([0.5, 8.5])\n",
    "xgoal= np.array([8.5, 8.5])\n",
    "\n",
    "mppi_params = dict(\n",
    "    # Task specification\n",
    "    dt=dt,\n",
    "    x0=x0,\n",
    "    xgoal=xgoal,\n",
    "    timesteps=timesteps,\n",
    "    u_seq0=u_seq0,\n",
    "\n",
    "    # For risk-aware min time planning\n",
    "    goal_tolerance=0.5,\n",
    "    v_post_rollout=0.01,\n",
    "    cvar_alpha=0.99, # use the mean if cvar_alpha=1.0\n",
    "\n",
    "    # Hyper parameters\n",
    "    lambda_weight=1.0,\n",
    "    num_opt=1,\n",
    "\n",
    "    # Control and sample specification\n",
    "    u_std=np.array([2.0, 2.0]),\n",
    "    vrange = np.array([0, 3]), \n",
    "    wrange=np.array([-np.pi, np.pi]),\n",
    ")\n",
    "\n",
    "\n",
    "mppi_planner = MPPI_Numba()\n",
    "mppi_planner.set_tdm(lin_tdm, ang_tdm)\n",
    "mppi_planner.set_params(mppi_params)\n",
    "mppi_planner.init_device_vars_before_solving()\n",
    "useq = mppi_planner.solve()\n",
    "%timeit useq = mppi_planner.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(useq[:,0], label='v')\n",
    "ax.plot(useq[:,1], label='w')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "lin_tdm_vis = TDM_Visualizer(lin_tdm)\n",
    "fig, ax = lin_tdm_vis.draw(figsize=(5, 5))\n",
    "ax.plot([x0[0]], [x0[1]], 'ro', markersize=10, label=\"Start\")\n",
    "c1 = plt.Circle(xgoal, mppi_params['goal_tolerance'], color='r', fill=False, label=\"Goal\")\n",
    "ax.add_patch(c1)\n",
    "\n",
    "# Rollout over sampled environments\n",
    "xhist = np.zeros((timesteps+1, 3))\n",
    "xhist[0] = x0\n",
    "for t in range(timesteps):\n",
    "  xhist[t+1, 0] = xhist[t, 0] + dt*np.cos(xhist[t, 2])*useq[t,0]\n",
    "  xhist[t+1, 1] = xhist[t, 1] + dt*np.sin(xhist[t, 2])*useq[t,0]\n",
    "  xhist[t+1, 2] = xhist[t, 2] + dt*useq[t,1]\n",
    "\n",
    "ax.plot(xhist[:,0], xhist[:,1])\n",
    "\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed-loop performance\n",
    "\n",
    "Given a sampled environment, do receiding horizon planning based on the sampled dynamics.\n",
    "* Color the traversed part as solid red\n",
    "* Color the future parts (over X presampled envs) of the optimal solution\n",
    "  * Do this in GPU as well? (Use already sampled batch on GPU, copy back a subset of the state trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, do in jupyter notebook by visualizing multiple frames of the problem\n",
    "\n",
    "# Fixed a sampled environment\n",
    "\n",
    "# Loop\n",
    "# Solve\n",
    "# Update state\n",
    "# Update MPPI state\n",
    "# Update Visualization\n",
    "# Goal check\n",
    "\n",
    "# Print performance info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58b5cbfff1d83ad9d05b0969843a32b2642f528421c5e92b91f2d8ed7d274ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
